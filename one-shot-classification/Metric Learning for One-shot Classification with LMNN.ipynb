{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings due to deprecation \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rng\n",
    "import numpy.linalg as alg\n",
    "\n",
    "import copy\n",
    "import metric_learn\n",
    "\n",
    "from scipy.ndimage import imread, affine_transform\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "from skimage.measure import block_reduce\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from functools import reduce\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nrun = 20 # number of classification runs\n",
    "fname_label = 'class_labels.txt' # where class labels are stored for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_run(folder,f_load,f_cost,ftype='cost'):\n",
    "    # Compute error rate for one run of one-shot classification\n",
    "    #\n",
    "    # Input\n",
    "    #  folder : contains images for a run of one-shot classification\n",
    "    #  f_load : itemA = f_load('file.png') should read in the image file and process it\n",
    "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
    "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
    "    #\n",
    "    # Output\n",
    "    #  perror : percent errors (0 to 100% error)\n",
    "    # \n",
    "    assert ((ftype=='cost') | (ftype=='score'))\n",
    "\n",
    "    # get file names\n",
    "    with open(folder+'/'+fname_label) as f:\n",
    "\t    content = f.read().splitlines()\n",
    "    pairs = [line.split() for line in content]\n",
    "    test_files  = [pair[0] for pair in pairs]\n",
    "    train_files = [pair[1] for pair in pairs]\n",
    "    answers_files = copy.copy(train_files)\n",
    "    test_files.sort()\n",
    "    train_files.sort()\t\n",
    "    ntrain = len(train_files)\n",
    "    ntest = len(test_files)\n",
    "\n",
    "    # load the images (and, if needed, extract features)\n",
    "    train_items = [f_load(f) for f in train_files]\n",
    "    test_items  = [f_load(f) for f in test_files ]\n",
    "\n",
    "    # Augment with 5 affine transforms\n",
    "    # Creates 6 total examples per training item\n",
    "    nexample = 6\n",
    "    feat_mtx = np.zeros((nexample*ntrain,1024),dtype=float)\n",
    "    for i, item in enumerate(train_items):\n",
    "        I = rescale(item, 1.0 / 3.0, anti_aliasing=False)\n",
    "        I = I.astype(bool)\n",
    "        I = I.astype(float)\n",
    "        feat_mtx[(nexample*i),:] = I.flatten()\n",
    "        for j in range(1,nexample):\n",
    "            feat_mtx[(nexample*i)+j,:] = AffineTransImg(item)\n",
    "\n",
    "    # gather the class numbers for each file\n",
    "    classes = np.repeat(np.arange(1,ntrain+1),nexample)\n",
    "\n",
    "    Y = classes\n",
    "    X = feat_mtx\n",
    "\n",
    "    # setting up LMNN\n",
    "    # tried 5 nearest neighbors (the 5 affine transforms of training data)\n",
    "    # Takes very long to train, so there is a block for preloaded matrices\n",
    "    lmnn = metric_learn.LMNN(k=5, min_iter=50, max_iter=1000, learn_rate=1e-6, regularization=1)\n",
    "\n",
    "    # fit the data!\n",
    "    # Could take up to 30 minutes per run\n",
    "    # Use already saved matrices to save time\n",
    "    try:\n",
    "        Minv = np.load(folder+'Minv.npy')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Matrix file not available.\\n\")\n",
    "        print(\"Fitting data...\\n\")\n",
    "        lmnn.fit(X, Y)\n",
    "    # Save Mahalanobis metric matrix as a file for later\n",
    "        Minv = lmnn.metric()\n",
    "        np.save(folder+'Minv.npy', Minv)\n",
    "    \n",
    "    \n",
    "\n",
    "    # compute cost matrix\n",
    "    costM = np.zeros((ntest,ntrain),float)\n",
    "    for i in range(ntest):\n",
    "\t    for c in range(ntrain):\n",
    "\t\t    costM[i,c] = f_cost(test_items[i],train_items[c],Minv)\n",
    "    \n",
    "    if ftype == 'cost':\n",
    "\t    YHAT = np.argmin(costM,axis=1)\n",
    "    elif ftype == 'score':\n",
    "\t    YHAT = np.argmax(costM,axis=1)\n",
    "    else:\n",
    "\t    assert False\n",
    "\n",
    "    # compute the error rate\n",
    "    correct = 0.0\n",
    "    for i in range(ntest):\n",
    "\t    if train_files[YHAT[i]] == answers_files[i]:\n",
    "\t\t    correct += 1.0\n",
    "    pcorrect = 100 * correct / ntest\n",
    "    perror = 100 - pcorrect\n",
    "    return perror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModHausdorffDistance(itemA,itemB,Minv):\n",
    "    # Modified Hausdorff Distance\n",
    "    #\n",
    "    # Input\n",
    "    #  itemA : [n x 2] coordinates of \"inked\" pixels\n",
    "    #  itemB : [m x 2] coordinates of \"inked\" pixels\n",
    "    #\n",
    "    #  M.-P. Dubuisson, A. K. Jain (1994). A modified hausdorff distance for object matching.\n",
    "    #  International Conference on Pattern Recognition, pp. 566-568.\n",
    "    #\n",
    "    itemA = rescale(itemA, 1.0 / 3.0, anti_aliasing=False).flatten()\n",
    "    itemB = rescale(itemB, 1.0 / 3.0, anti_aliasing=False).flatten()\n",
    "    \n",
    "    items = np.stack((itemA, itemB))\n",
    "    D = pdist(items, metric='mahalanobis', VI=Minv)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadImgAsPoints(fn):\n",
    "    # Load image file and return coordinates of 'inked' pixels in the binary image\n",
    "    # \n",
    "    # Output:\n",
    "    #  D : [n x 2] rows are coordinates\n",
    "    I = imread(fn,flatten=True)\n",
    "    I = np.array(I,dtype=bool)\n",
    "    I = np.logical_not(I)\n",
    "\n",
    "    # crop it to 96x96 for easy rescaling\n",
    "    I = I[4:100,4:100]\n",
    "    #I = rescale(I, 1.0 / 3.0, anti_aliasing=False)\n",
    "    #I = resize(I, (I.shape[0] / 3, I.shape[1] / 3), anti_aliasing=False)\n",
    "    #I = downscale_local_mean(I, (3, 3))\n",
    "    #I = I.astype(bool)\n",
    "    #I = I.astype(float)\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AffineTransImg(I):\n",
    "    # Input: \n",
    "    # Image ndarray of floats\n",
    "    #\n",
    "    # Output:\n",
    "    # Affine tranformed image, flattened to 1D\n",
    "    theta = rng.uniform(-np.pi/18, np.pi/18)\n",
    "    rhox = rng.uniform(-0.1,0.1)\n",
    "    rhoy = rng.uniform(-0.1,0.1)\n",
    "    sx = rng.uniform(0.9,1.1)\n",
    "    sy = rng.uniform(0.9,1.1)\n",
    "    tx = rng.uniform(-2,2)\n",
    "    ty = rng.uniform(-2,2)\n",
    "    c = np.cos(theta)\n",
    "    s = np.sin(theta)\n",
    "    Rot = np.array([[c,s],[-s,c]])\n",
    "    Shr = np. array([[1,rhox],[rhoy,1]])\n",
    "    Sca = np.array([[sx,0],[0,sy]])\n",
    "    A = reduce(np.dot, [Sca, Shr, Rot])\n",
    "    b = np.transpose([[0,0]])\n",
    "    try:\n",
    "        Ainv = alg.inv(A)\n",
    "        HomoA = np.concatenate((Ainv,-np.dot(Ainv,b)),axis=1)\n",
    "        HomoA = np.concatenate((HomoA,[[0,0,1]]))\n",
    "        I = affine_transform(I, Ainv)\n",
    "    except np.linalg.LinAlgError as err:\n",
    "        if 'Singular matrix' in str(err):\n",
    "            pass\n",
    "        else:\n",
    "            raise     \n",
    "    I = downscale_local_mean(I, (3, 3))\n",
    "    I[I >= 0.5] = 1\n",
    "    I[I < 0.5] = 0\n",
    "    \n",
    "    I = I.flatten()\n",
    "    return(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-shot classification demo with Large Margin Nearest Neighbors\n",
      " run 1 (error 75.0%)\n",
      " run 2 (error 95.0%)\n",
      " run 3 (error 95.0%)\n",
      " run 4 (error 90.0%)\n",
      " run 5 (error 85.0%)\n",
      " run 6 (error 90.0%)\n",
      " run 7 (error 100.0%)\n",
      " run 8 (error 95.0%)\n",
      " run 9 (error 90.0%)\n",
      " run 10 (error 100.0%)\n",
      " run 11 (error 95.0%)\n",
      " run 12 (error 85.0%)\n",
      " run 13 (error 85.0%)\n",
      " run 14 (error 80.0%)\n",
      " run 15 (error 95.0%)\n",
      " run 16 (error 90.0%)\n",
      " run 17 (error 95.0%)\n",
      " run 18 (error 85.0%)\n",
      " run 19 (error 90.0%)\n",
      " run 20 (error 95.0%)\n",
      " average error 90.5%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\t#\n",
    "\t# Running this demo should lead to a result of 38.8 percent errors.\n",
    "\t#\n",
    "\t#   M.-P. Dubuisson, A. K. Jain (1994). A modified hausdorff distance for object matching.\n",
    "\t#     International Conference on Pattern Recognition, pp. 566-568.\n",
    "\t#\n",
    "\t# ** Models should be trained on images in 'images_background' directory to avoid \n",
    "\t#  using images and alphabets used in the one-shot evaluation **\n",
    "\t#\n",
    "\tprint ('One-shot classification demo with Large Margin Nearest Neighbors')\n",
    "\tperror = np.zeros(nrun)\n",
    "\tfor r in range(1,nrun+1):\n",
    "\t\trs = str(r)\n",
    "\t\tif len(rs)==1:\n",
    "\t\t\trs = '0' + rs\t\t\n",
    "\t\tperror[r-1] = classification_run('run'+rs, LoadImgAsPoints, ModHausdorffDistance, 'cost')\n",
    "\t\tprint (\" run \" + str(r) + \" (error \" + str(\tperror[r-1] ) + \"%)\")\t\t\n",
    "\ttotal = np.mean(perror)\n",
    "\tprint (\" average error \" + str(total) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this metric learning method, the error is very large. In fact this technique only resulted in error close to random guessing (90.5% vs 95%). Unfortunately the LMNN algorithm as implemented is very slow. It might improve if the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
